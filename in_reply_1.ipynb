{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/keras/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import datetime\n",
    "import searchtweets\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_list = ['AwkwardRambler','AngryBlackN8V',\n",
    "             'Pandabbadon', 'LammaticHama','DeadDogLake',\n",
    "             'cricketcrocker','devilishgrin000','LowArctic',\n",
    "             'ChelseyMooner','akayatuk','nativeopinion',\n",
    "             'BadSalishHeart','joyem_braun','RuthH_Hopkins',\n",
    "             'brettachapman','NativeApprops','Pam_Palmater',\n",
    "             'AzieDee','BigIndianGyasi','RoanhorseBex',\n",
    "             'Leave_Matoaka','ZoeSTodd',\n",
    "             'notvanishing','Dallas_Hunt','justicedanielh',\n",
    "             'WordsandGuitar','tuckeve','tagaq',\n",
    "             'TanyaTalaga','Hayden_King','gindaanis',\n",
    "             'antalalakam','dearnonnatives','VinceSchilling',\n",
    "             'DelSchilling','LowaBeebe',\n",
    "             'llewellynjobs','DaveAlexRoberts','SaltyLilOjibwe',\n",
    "             'DarrylLeroux','mredshirtshaw','mors_lakota',\n",
    "             'Ruth4Nd','Indigenia','ItazipcoLakota',\n",
    "             'ryanredcorn','KimTallBear','tanayawinder',\n",
    "             'shotheekwe','msimmons444','powhatannative',\n",
    "             'aliwatson117','jfkeeler','ThunderingElks',\n",
    "             'FrankWaln','AgentNdn','DeLesslin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(curated_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @justicedanielh, @KimTallBear on curated list also\n",
    "\n",
    "I_scholars_list = ['justicedanielh', 'PepePierce', 'pollysgdaughter', 'rebeccanagle', 'KimTallBear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get historical tweets from curated list & scholars\n",
    "# might as well do it all at once\n",
    "\n",
    "full_list = ['AwkwardRambler','AngryBlackN8V',\n",
    "             'Pandabbadon', 'LammaticHama','DeadDogLake',\n",
    "             'cricketcrocker','devilishgrin000','LowArctic',\n",
    "             'ChelseyMooner','akayatuk','nativeopinion',\n",
    "             'BadSalishHeart','joyem_braun','RuthH_Hopkins',\n",
    "             'brettachapman','NativeApprops','Pam_Palmater',\n",
    "             'AzieDee','BigIndianGyasi','RoanhorseBex',\n",
    "             'Leave_Matoaka','ZoeSTodd',\n",
    "             'notvanishing','Dallas_Hunt','justicedanielh',\n",
    "             'WordsandGuitar','tuckeve','tagaq',\n",
    "             'TanyaTalaga','Hayden_King','gindaanis',\n",
    "             'antalalakam','dearnonnatives','VinceSchilling',\n",
    "             'DelSchilling','LowaBeebe',\n",
    "             'llewellynjobs','DaveAlexRoberts','SaltyLilOjibwe',\n",
    "             'DarrylLeroux','mredshirtshaw','mors_lakota',\n",
    "             'Ruth4Nd','Indigenia','ItazipcoLakota',\n",
    "             'ryanredcorn','KimTallBear','tanayawinder',\n",
    "             'shotheekwe','msimmons444','powhatannative',\n",
    "             'aliwatson117','jfkeeler','ThunderingElks',\n",
    "             'FrankWaln','AgentNdn','DeLesslin',\n",
    "             'PepePierce','pollysgdaughter','rebeccanagle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_object(search_term, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "    \n",
    "    '''\n",
    "    takes date range, screen name & number of tweets\n",
    "    \n",
    "    search returns replies to input screen name\n",
    "    \n",
    "    returns tweets object\n",
    "    \n",
    "    input search term as a string\n",
    "    \n",
    "    input search range as datetime.datetime(20xx, 1, 20)\n",
    "    \n",
    "    include_retweets defaults is True. to exclude retweets set to False.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    search_args = searchtweets.load_credentials('twitter_keys.yaml',\n",
    "                                                yaml_key='search_tweets_api',\n",
    "                                                env_overwrite=False)\n",
    "    \n",
    "    if include_retweets:\n",
    "        \n",
    "        #search_term = search_term + ' lang:en'\n",
    "        \n",
    "        search_term = '(to:' + search_term + ') is:reply lang:en'\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #search_term = search_term + ' lang:en -is:retweet'\n",
    "        \n",
    "        search_term = '(to:' + search_term + ') is:reply lang:en -is:retweet'\n",
    "        \n",
    "    \n",
    "    \n",
    "    rule = searchtweets.gen_rule_payload(search_term,\n",
    "                                         results_per_call=500,\n",
    "                                         from_date=start_date.strftime('%Y-%m-%d'),\n",
    "                                         to_date=end_date.strftime('%Y-%m-%d'))     \n",
    "        \n",
    "    tweet_objects = []\n",
    "    \n",
    "    rs = searchtweets.ResultStream(rule_payload=rule,\n",
    "                                   max_results=num_of_tweets,\n",
    "                                   max_pages= num_of_tweets / 500,\n",
    "                                   **search_args)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, tweet_object in enumerate(rs.stream(), start=1):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            \n",
    "            now = time.time()\n",
    "            \n",
    "            if now < start_time + 4:\n",
    "                \n",
    "                time.sleep(4 - (now - start_time))\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "        tweet_objects.append(tweet_object)\n",
    "    \n",
    "    return tweet_objects\n",
    "\n",
    "def tweet_obj_to_df(tweet_objects):\n",
    "    \n",
    "    tweet_dict = {'text': [],\n",
    "                  'author': [],\n",
    "                  'replying_to': []\n",
    "                 }\n",
    "    \n",
    "    for tweet in tweet_objects:\n",
    "        \n",
    "        tweet_dict['text'].append(tweet.all_text)\n",
    "        \n",
    "        tweet_dict['author'].append(tweet.screen_name)\n",
    "        \n",
    "        tweet_dict['replying_to'].append(tweet.in_reply_to_screen_name)\n",
    "    \n",
    "    tweets_df = pd.DataFrame(tweet_dict)\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 \n",
      "\n",
      "                                                 text           author  \\\n",
      "0   @rebeccanagle Sound like a Bernie Slogan... #N...  RichardFerreiro   \n",
      "1                              @rebeccanagle Truth!!!      bear_daddys   \n",
      "2                   @rebeccanagle That sounds “great”         jbecks74   \n",
      "3   @rebeccanagle @KimTallBear @highcountrynews I ...        Jamie_Maz   \n",
      "4   @rebeccanagle is there anyway you remember the...     nrtankersley   \n",
      "5   @rebeccanagle @peterdaou The same publication ...  A_Savage_Indian   \n",
      "6   @rebeccanagle @DianeSnavely @KimTallBear @high...   TammyKosiancic   \n",
      "7   @rebeccanagle @DianeSnavely @KimTallBear @high...   TammyKosiancic   \n",
      "8   @rebeccanagle Nishnabè which sort of translate...       sour_utley   \n",
      "9   @rebeccanagle Kanieknehake, means People of th...  wrdswthstranger   \n",
      "10  @rebeccanagle @peterdaou I knew nothing about ...       ObserverPa   \n",
      "11  @rebeccanagle @highcountrynews @KimTallBear A ...           TomLeb   \n",
      "12  @rebeccanagle @highcountrynews @KimTallBear JF...       swampsteve   \n",
      "13  @rebeccanagle I like what you said about Berni...     LindaZehrung   \n",
      "14  @rebeccanagle @Blackamazon There is a movie ab...   Crazatbirth101   \n",
      "15  @rebeccanagle He lets his staffers take the ba...      Kayetim0312   \n",
      "16  @rebeccanagle How horrifying that not everybod...          Red_XIV   \n",
      "17  @rebeccanagle Same. I also think it's telling ...        lilyarc77   \n",
      "18  @rebeccanagle Not all violence is felt equally...        Sfreemont   \n",
      "19  @rebeccanagle Grateful for the insights you sh...      AmySommers1   \n",
      "\n",
      "     replying_to  \n",
      "0   rebeccanagle  \n",
      "1   rebeccanagle  \n",
      "2   rebeccanagle  \n",
      "3   rebeccanagle  \n",
      "4   rebeccanagle  \n",
      "5   rebeccanagle  \n",
      "6   rebeccanagle  \n",
      "7   rebeccanagle  \n",
      "8   rebeccanagle  \n",
      "9   rebeccanagle  \n",
      "10  rebeccanagle  \n",
      "11  rebeccanagle  \n",
      "12  rebeccanagle  \n",
      "13  rebeccanagle  \n",
      "14  rebeccanagle  \n",
      "15  rebeccanagle  \n",
      "16  rebeccanagle  \n",
      "17  rebeccanagle  \n",
      "18  rebeccanagle  \n",
      "19  rebeccanagle  \n"
     ]
    }
   ],
   "source": [
    "# get_tweet_object(search_term, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "\n",
    "# search_term = '(to:USERNAME) is:reply'\n",
    "\n",
    "test_tweet_object = get_tweet_object('rebeccanagle', datetime.datetime(2018, 1, 1), datetime.datetime(2020, 1, 26), 100, include_retweets=False)\n",
    "\n",
    "test_tweets_df = tweet_obj_to_df(test_tweet_object)\n",
    "\n",
    "print(len(test_tweets_df), '\\n')\n",
    "\n",
    "print(test_tweets_df.head(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'll be looking at about sixty accounts, a function will make things easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_dataframes(search_list, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "    \n",
    "    '''\n",
    "    takes a list of twitter screen names & date range\n",
    "    returns a dataframe with replies to that screen name\n",
    "    within the provided time range\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for search_term in search_list:\n",
    "        \n",
    "        tweet_object = get_tweet_object(search_term, start_date, end_date, num_of_tweets, include_retweets=include_retweets)\n",
    "        \n",
    "        tweets_raw_df = tweet_obj_to_df(tweet_object)\n",
    "        \n",
    "        df = df.append(tweets_raw_df, ignore_index=True)\n",
    "        \n",
    "        print('In reply to ', search_term, 'dataset length: ', len(tweets_raw_df), '\\n')\n",
    "        \n",
    "        print(tweets_raw_df.head(20), '\\n')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In reply to  justicedanielh dataset length:  100 \n",
      "\n",
      "                                                 text           author  \\\n",
      "0   @justicedanielh Yep. I just read Wild Seed.......      joyfulcarla   \n",
      "1   @justicedanielh, hahaha. When I first saw that...         debreese   \n",
      "2   @justicedanielh @NativeApprops I am in Thunder...         debreese   \n",
      "3   @justicedanielh, no doubt that all this stuff ...         debreese   \n",
      "4   @justicedanielh @NativeApprops @MissusTWalker ...         debreese   \n",
      "5   @justicedanielh And then there's self-proclaim...          clclyne   \n",
      "6   @justicedanielh Have you been watching CLEVERM...     annegalloway   \n",
      "7   @justicedanielh also being mestizo is much eas...  ChimalpahinXIII   \n",
      "8   @justicedanielh also it seems Spain with it's ...  ChimalpahinXIII   \n",
      "9   @justicedanielh the eastern nations never got ...  ChimalpahinXIII   \n",
      "10  @justicedanielh I guess it's also because we w...  ChimalpahinXIII   \n",
      "11  @justicedanielh it's weirs huh? Even in Canada...  ChimalpahinXIII   \n",
      "12  @justicedanielh overstep boundaries and disres...  ellycrackermann   \n",
      "13  @justicedanielh I ask because I am trying to r...  ellycrackermann   \n",
      "14  @justicedanielh fractured paperwork, is there ...  ellycrackermann   \n",
      "15  @justicedanielh as a descendant of those who l...  ellycrackermann   \n",
      "16  @justicedanielh ironically we've the opposite ...  ChimalpahinXIII   \n",
      "17  @justicedanielh Because the ties of heritage a...   justicedanielh   \n",
      "18  @justicedanielh Can't expect that everyone who...   justicedanielh   \n",
      "19  @justicedanielh No to self-flagellate, but my ...      OrionKidder   \n",
      "\n",
      "       replying_to  \n",
      "0   justicedanielh  \n",
      "1   justicedanielh  \n",
      "2   justicedanielh  \n",
      "3   justicedanielh  \n",
      "4   justicedanielh  \n",
      "5   justicedanielh  \n",
      "6   justicedanielh  \n",
      "7   justicedanielh  \n",
      "8   justicedanielh  \n",
      "9   justicedanielh  \n",
      "10  justicedanielh  \n",
      "11  justicedanielh  \n",
      "12  justicedanielh  \n",
      "13  justicedanielh  \n",
      "14  justicedanielh  \n",
      "15  justicedanielh  \n",
      "16  justicedanielh  \n",
      "17  justicedanielh  \n",
      "18  justicedanielh  \n",
      "19  justicedanielh   \n",
      "\n",
      "In reply to  PepePierce dataset length:  69 \n",
      "\n",
      "                                                 text           author  \\\n",
      "0   @PepePierce The feeling is entirely mutual. St...   justicedanielh   \n",
      "1   @PepePierce thank YOU! wise words and beautifu...      NoahRemnick   \n",
      "2   @PepePierce @TheBookstage @SalmaiaLit @eternac...    julianlopezok   \n",
      "3                         @PepePierce AMEN BROTHER!!!  mayberrymatt4u2   \n",
      "4               @PepePierce Thank you for writing it!   BruceMatsunaga   \n",
      "5   @PepePierce Your beautiful essay about identit...    twotiredgeese   \n",
      "6                        @PepePierce haha, I love it!       robohontas   \n",
      "7                          @PepePierce nice … thanks!     ashoncrawley   \n",
      "8   @PepePierce Interesting! Still so strange to m...    alwaystheself   \n",
      "9   @PepePierce Like, a private convo at a confere...    alwaystheself   \n",
      "10  .@PepePierce Publicly challenging? I haven't s...    alwaystheself   \n",
      "11          @Racelawhistory thanks for the support!!!       PepePierce   \n",
      "12  TY @PepePierce @marthasjonesUM this is a perfe...           WeirMB   \n",
      "13                 @PepePierce Thanks for the follow!  QueerStudiesOSU   \n",
      "14       @PepePierce linked to yr post btw on my blog        rosswolfe   \n",
      "15                 @PepePierce beautifully compelling        LaDeziree   \n",
      "16  @PepePierce nails it. In Search of an Authenti...   herreraylozano   \n",
      "17                             @PepePierce thank YOU.        klsealegs   \n",
      "18  @PepePierce wasn't that Cairanne tasty? Glad t...      TuckShopMTL   \n",
      "19  @PepePierce Many thanks for the follow #thegat...     studyabroad8   \n",
      "\n",
      "   replying_to  \n",
      "0   PepePierce  \n",
      "1   PepePierce  \n",
      "2   PepePierce  \n",
      "3   PepePierce  \n",
      "4   PepePierce  \n",
      "5   PepePierce  \n",
      "6   PepePierce  \n",
      "7   PepePierce  \n",
      "8   PepePierce  \n",
      "9   PepePierce  \n",
      "10  PepePierce  \n",
      "11  PepePierce  \n",
      "12  PepePierce  \n",
      "13  PepePierce  \n",
      "14  PepePierce  \n",
      "15  PepePierce  \n",
      "16  PepePierce  \n",
      "17  PepePierce  \n",
      "18  PepePierce  \n",
      "19  PepePierce   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get_raw_dataframes(search_list, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "\n",
    "short_test_list = ['justicedanielh', 'PepePierce']\n",
    "\n",
    "test_df = get_raw_dataframes(short_test_list, datetime.datetime(2007,1,1), datetime.datetime(2016,7,1), 100, include_retweets=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Date Ranges\n",
    "\n",
    "I'll be testing 3 date ranges to try to see whether sentiment towards Natives (as measured in replies) has changed significantly over the past several years. I am looking at two main \"events\" (although they are not exactly discrete): the 2016 election, and 2018, when Senator Elizabeth Warren was first mockingly referred to as \"Pocahontas\" by President Donald Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Period I: pre-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
