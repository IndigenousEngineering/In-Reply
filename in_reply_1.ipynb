{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/keras/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import datetime\n",
    "import searchtweets\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_list = ['AwkwardRambler','AngryBlackN8V',\n",
    "             'Pandabbadon', 'LammaticHama','DeadDogLake',\n",
    "             'cricketcrocker','devilishgrin000','LowArctic',\n",
    "             'ChelseyMooner','akayatuk','nativeopinion',\n",
    "             'BadSalishHeart','joyem_braun','RuthH_Hopkins',\n",
    "             'brettachapman','NativeApprops','Pam_Palmater',\n",
    "             'AzieDee','BigIndianGyasi','RoanhorseBex',\n",
    "             'Leave_Matoaka','ZoeSTodd',\n",
    "             'notvanishing','Dallas_Hunt','justicedanielh',\n",
    "             'WordsandGuitar','tuckeve','tagaq',\n",
    "             'TanyaTalaga','Hayden_King','gindaanis',\n",
    "             'antalalakam','dearnonnatives','VinceSchilling',\n",
    "             'DelSchilling','LowaBeebe',\n",
    "             'llewellynjobs','DaveAlexRoberts','SaltyLilOjibwe',\n",
    "             'DarrylLeroux','mredshirtshaw','mors_lakota',\n",
    "             'Ruth4Nd','Indigenia','ItazipcoLakota',\n",
    "             'ryanredcorn','KimTallBear','tanayawinder',\n",
    "             'shotheekwe','msimmons444','powhatannative',\n",
    "             'aliwatson117','jfkeeler','ThunderingElks',\n",
    "             'FrankWaln','AgentNdn','DeLesslin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "print(len(curated_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @justicedanielh, @KimTallBear on curated list also\n",
    "\n",
    "I_scholars_list = ['justicedanielh', 'PepePierce', 'pollysgdaughter', 'rebeccanagle', 'KimTallBear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get historical tweets from curated list & scholars\n",
    "# might as well do it all at once\n",
    "\n",
    "full_list = ['AwkwardRambler','AngryBlackN8V',\n",
    "             'Pandabbadon', 'LammaticHama','DeadDogLake',\n",
    "             'cricketcrocker','devilishgrin000','LowArctic',\n",
    "             'ChelseyMooner','akayatuk','nativeopinion',\n",
    "             'BadSalishHeart','joyem_braun','RuthH_Hopkins',\n",
    "             'brettachapman','NativeApprops','Pam_Palmater',\n",
    "             'AzieDee','BigIndianGyasi','RoanhorseBex',\n",
    "             'Leave_Matoaka','ZoeSTodd',\n",
    "             'notvanishing','Dallas_Hunt','justicedanielh',\n",
    "             'WordsandGuitar','tuckeve','tagaq',\n",
    "             'TanyaTalaga','Hayden_King','gindaanis',\n",
    "             'antalalakam','dearnonnatives','VinceSchilling',\n",
    "             'DelSchilling','LowaBeebe',\n",
    "             'llewellynjobs','DaveAlexRoberts','SaltyLilOjibwe',\n",
    "             'DarrylLeroux','mredshirtshaw','mors_lakota',\n",
    "             'Ruth4Nd','Indigenia','ItazipcoLakota',\n",
    "             'ryanredcorn','KimTallBear','tanayawinder',\n",
    "             'shotheekwe','msimmons444','powhatannative',\n",
    "             'aliwatson117','jfkeeler','ThunderingElks',\n",
    "             'FrankWaln','AgentNdn','DeLesslin',\n",
    "             'PepePierce','pollysgdaughter','rebeccanagle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_object(search_term, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "    \n",
    "    '''\n",
    "    takes date range, screen name & number of tweets\n",
    "    \n",
    "    search returns replies to input screen name\n",
    "    \n",
    "    returns tweets object\n",
    "    \n",
    "    input search term as a string\n",
    "    \n",
    "    input search range as datetime.datetime(20xx, 1, 20)\n",
    "    \n",
    "    include_retweets defaults is True. to exclude retweets set to False.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    search_args = searchtweets.load_credentials('twitter_keys.yaml',\n",
    "                                                yaml_key='search_tweets_api',\n",
    "                                                env_overwrite=False)\n",
    "    \n",
    "    if include_retweets:\n",
    "        \n",
    "        #search_term = search_term + ' lang:en'\n",
    "        \n",
    "        search_term = '(to:' + search_term + ') is:reply lang:en'\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #search_term = search_term + ' lang:en -is:retweet'\n",
    "        \n",
    "        search_term = '(to:' + search_term + ') is:reply lang:en -is:retweet'\n",
    "        \n",
    "    \n",
    "    \n",
    "    rule = searchtweets.gen_rule_payload(search_term,\n",
    "                                         results_per_call=500,\n",
    "                                         from_date=start_date.strftime('%Y-%m-%d'),\n",
    "                                         to_date=end_date.strftime('%Y-%m-%d'))     \n",
    "        \n",
    "    tweet_objects = []\n",
    "    \n",
    "    rs = searchtweets.ResultStream(rule_payload=rule,\n",
    "                                   max_results=num_of_tweets,\n",
    "                                   max_pages= num_of_tweets / 500,\n",
    "                                   **search_args)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, tweet_object in enumerate(rs.stream(), start=1):\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            \n",
    "            now = time.time()\n",
    "            \n",
    "            if now < start_time + 4:\n",
    "                \n",
    "                time.sleep(4 - (now - start_time))\n",
    "                \n",
    "                start_time = time.time()\n",
    "                \n",
    "        tweet_objects.append(tweet_object)\n",
    "    \n",
    "    return tweet_objects\n",
    "\n",
    "def tweet_obj_to_df(tweet_objects):\n",
    "    \n",
    "    tweet_dict = {'text': [],\n",
    "                  'author': [],\n",
    "                  'replying_to': []\n",
    "                 }\n",
    "    \n",
    "    for tweet in tweet_objects:\n",
    "        \n",
    "        tweet_dict['text'].append(tweet.all_text)\n",
    "        \n",
    "        tweet_dict['author'].append(tweet.screen_name)\n",
    "        \n",
    "        tweet_dict['replying_to'].append(tweet.in_reply_to_screen_name)\n",
    "    \n",
    "    tweets_df = pd.DataFrame(tweet_dict)\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 \n",
      "\n",
      "                                                 text           author  \\\n",
      "0   @rebeccanagle Sound like a Bernie Slogan... #N...  RichardFerreiro   \n",
      "1                              @rebeccanagle Truth!!!      bear_daddys   \n",
      "2                   @rebeccanagle That sounds “great”         jbecks74   \n",
      "3   @rebeccanagle @KimTallBear @highcountrynews I ...        Jamie_Maz   \n",
      "4   @rebeccanagle is there anyway you remember the...     nrtankersley   \n",
      "5   @rebeccanagle @peterdaou The same publication ...  A_Savage_Indian   \n",
      "6   @rebeccanagle @DianeSnavely @KimTallBear @high...   TammyKosiancic   \n",
      "7   @rebeccanagle @DianeSnavely @KimTallBear @high...   TammyKosiancic   \n",
      "8   @rebeccanagle Nishnabè which sort of translate...       sour_utley   \n",
      "9   @rebeccanagle Kanieknehake, means People of th...  wrdswthstranger   \n",
      "10  @rebeccanagle @peterdaou I knew nothing about ...       ObserverPa   \n",
      "11  @rebeccanagle @highcountrynews @KimTallBear A ...           TomLeb   \n",
      "12  @rebeccanagle @highcountrynews @KimTallBear JF...       swampsteve   \n",
      "13  @rebeccanagle I like what you said about Berni...     LindaZehrung   \n",
      "14  @rebeccanagle @Blackamazon There is a movie ab...   Crazatbirth101   \n",
      "15  @rebeccanagle He lets his staffers take the ba...      Kayetim0312   \n",
      "16  @rebeccanagle How horrifying that not everybod...          Red_XIV   \n",
      "17  @rebeccanagle Same. I also think it's telling ...        lilyarc77   \n",
      "18  @rebeccanagle Not all violence is felt equally...        Sfreemont   \n",
      "19  @rebeccanagle Grateful for the insights you sh...      AmySommers1   \n",
      "\n",
      "     replying_to  \n",
      "0   rebeccanagle  \n",
      "1   rebeccanagle  \n",
      "2   rebeccanagle  \n",
      "3   rebeccanagle  \n",
      "4   rebeccanagle  \n",
      "5   rebeccanagle  \n",
      "6   rebeccanagle  \n",
      "7   rebeccanagle  \n",
      "8   rebeccanagle  \n",
      "9   rebeccanagle  \n",
      "10  rebeccanagle  \n",
      "11  rebeccanagle  \n",
      "12  rebeccanagle  \n",
      "13  rebeccanagle  \n",
      "14  rebeccanagle  \n",
      "15  rebeccanagle  \n",
      "16  rebeccanagle  \n",
      "17  rebeccanagle  \n",
      "18  rebeccanagle  \n",
      "19  rebeccanagle  \n"
     ]
    }
   ],
   "source": [
    "# get_tweet_object(search_term, start_date, end_date, num_of_tweets, include_retweets=True):\n",
    "\n",
    "# search_term = '(to:USERNAME) is:reply'\n",
    "\n",
    "test_tweet_object = get_tweet_object('rebeccanagle', datetime.datetime(2018, 1, 1), datetime.datetime(2020, 1, 26), 100, include_retweets=False)\n",
    "\n",
    "test_tweets_df = tweet_obj_to_df(test_tweet_object)\n",
    "\n",
    "print(len(test_tweets_df), '\\n')\n",
    "\n",
    "print(test_tweets_df.head(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(to: username ) is:reply\n"
     ]
    }
   ],
   "source": [
    "#search_term = '(to:USERNAME) is:reply'\n",
    "\n",
    "searchy_term = 'username'\n",
    "\n",
    "print('(to:',searchy_term,') is:reply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
